---
source: /Users/hinrayleung/Documents/BNU/dataAna/PPT/第9章+大数据处理平台Flink.pdf
type: pdf
model: mistral-ocr-latest
processed: 2026-01-03T23:40:55.607992
---

# Document: 第9章+大数据处理平台Flink.pdf

## Table of Contents

- [Page 1](#page-1)
- [Page 2](#page-2)
- [Page 3](#page-3)
- [Page 4](#page-4)
- [Page 5](#page-5)
- [Page 6](#page-6)
- [Page 7](#page-7)
- [Page 8](#page-8)
- [Page 9](#page-9)
- [Page 10](#page-10)
- [Page 11](#page-11)
- [Page 12](#page-12)
- [Page 13](#page-13)
- [Page 14](#page-14)
- [Page 15](#page-15)
- [Page 16](#page-16)
- [Page 17](#page-17)
- [Page 18](#page-18)
- [Page 19](#page-19)
- [Page 20](#page-20)
- [Page 21](#page-21)
- [Page 22](#page-22)
- [Page 23](#page-23)
- [Page 24](#page-24)
- [Page 25](#page-25)
- [Page 26](#page-26)
- [Page 27](#page-27)
- [Page 28](#page-28)
- [Page 29](#page-29)
- [Page 30](#page-30)
- [Page 31](#page-31)
- [Page 32](#page-32)
- [Page 33](#page-33)
- [Page 34](#page-34)
- [Page 35](#page-35)
- [Page 36](#page-36)
- [Page 37](#page-37)
- [Page 38](#page-38)
- [Page 39](#page-39)
- [Page 40](#page-40)
- [Page 41](#page-41)
- [Page 42](#page-42)
- [Page 43](#page-43)
- [Page 44](#page-44)
- [Page 45](#page-45)
- [Page 46](#page-46)
- [Page 47](#page-47)
- [Page 48](#page-48)
- [Page 49](#page-49)
- [Page 50](#page-50)
- [Page 51](#page-51)
- [Page 52](#page-52)
- [Page 53](#page-53)
- [Page 54](#page-54)
- [Page 55](#page-55)
- [Page 56](#page-56)
- [Page 57](#page-57)
- [Page 58](#page-58)
- [Page 59](#page-59)
- [Page 60](#page-60)
- [Page 61](#page-61)
- [Page 62](#page-62)
- [Page 63](#page-63)
- [Page 64](#page-64)
- [Page 65](#page-65)
- [Page 66](#page-66)
- [Page 67](#page-67)
- [Page 68](#page-68)
- [Page 69](#page-69)
- [Page 70](#page-70)
- [Page 71](#page-71)
- [Page 72](#page-72)
- [Page 73](#page-73)
- [Page 74](#page-74)
- [Page 75](#page-75)
- [Page 76](#page-76)
- [Page 77](#page-77)
- [Page 78](#page-78)
- [Page 79](#page-79)
- [Page 80](#page-80)
- [Page 81](#page-81)
- [Page 82](#page-82)
- [Page 83](#page-83)
- [Page 84](#page-84)
- [Page 85](#page-85)
- [Page 86](#page-86)
- [Page 87](#page-87)
- [Page 88](#page-88)
- [Page 89](#page-89)
- [Page 90](#page-90)
- [Page 91](#page-91)
- [Page 92](#page-92)
- [Page 93](#page-93)
- [Page 94](#page-94)
- [Page 95](#page-95)
- [Page 96](#page-96)
- [Page 97](#page-97)
- [Page 98](#page-98)
- [Page 99](#page-99)
- [Page 100](#page-100)
- [Page 101](#page-101)
- [Page 102](#page-102)
- [Page 103](#page-103)
- [Page 104](#page-104)
- [Page 105](#page-105)
- [Page 106](#page-106)
- [Page 107](#page-107)
- [Page 108](#page-108)
- [Page 109](#page-109)
- [Page 110](#page-110)
- [Page 111](#page-111)
- [Page 112](#page-112)
- [Page 113](#page-113)
- [Page 114](#page-114)
- [Page 115](#page-115)
- [Page 116](#page-116)
- [Page 117](#page-117)
- [Page 118](#page-118)
- [Page 119](#page-119)
- [Page 120](#page-120)
- [Page 121](#page-121)
- [Page 122](#page-122)
- [Page 123](#page-123)
- [Page 124](#page-124)
- [Page 125](#page-125)
- [Page 126](#page-126)
- [Page 127](#page-127)
- [Page 128](#page-128)
- [Page 129](#page-129)
- [Page 130](#page-130)
- [Page 131](#page-131)
- [Page 132](#page-132)
- [Page 133](#page-133)
- [Page 134](#page-134)
- [Page 135](#page-135)
- [Page 136](#page-136)
- [Page 137](#page-137)
- [Page 138](#page-138)
- [Page 139](#page-139)
- [Page 140](#page-140)
- [Page 141](#page-141)
- [Page 142](#page-142)
- [Page 143](#page-143)

## Page 1

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 第9章 大数据处理平台Flink

## Page 2

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 主要内容

9.1 Flink概述
9.2 DataStream API
9.3 时间和窗口
9.4 状态和容错机制
9.5 Flink CEP

2

## Page 3

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink概述

Apache Flink

# 发展历史

- Flink是Apache软件基金会的一个顶级项目，是为分布式、高性能、随时可用以及准确的流处理应用程序打造的开源流处理框架，并且可以同时支持实时计算和批量计算。
- Flink起源于Stratosphere 项目，该项目是在2010年到2014年间由柏林工业大学、柏林洪堡大学和哈索普拉特纳研究所联合开展的。
- 2014年4月，Stratosphere代码被贡献给Apache软件基金会，成为Apache软件基金会孵化器项目。

## Page 4

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink概述

# Apache Flink: Stateful Computations over Data Streams

![img-0.jpeg](img-0.jpeg)

4

## Page 5

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink概述

## Flink应用场景

### 1. 事件驱动应用程序

- 事件驱动应用程序是一类有状态的应用程序，它从一个或多个事件流中提取事件，并通过触发计算、状态更新操作对传入的事件做出响应。
- 事件驱动应用程序是传统应用程序设计的演变，具有分离的计算和数据存储层。

![img-1.jpeg](img-1.jpeg)

传统应用程序的事件通常直接来自Web请求，需要远程读写事务型数据库。

事件驱动应用程序的数据则以事件日志的形式摄入，这些数据可以在本地访问，处理后的数据可以触发新事件或者写入事件日志。

5

## Page 6

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink概述

## Flink应用场景

### 2. 数据分析应用程序

- 数据分析应用程序用于从原始数据集中提取有价值的信息和指标进行分析，分析结果会应用到企业的决策、销售、管理等领域。
- 数据分析应用程序可分为批处理和流处理。

![img-2.jpeg](img-2.jpeg)

批处理的数据分析程序，从历史事件中读取数据，对数据进行操作后，可以直接写入数据库或HDFS，也可以直接生成报告。

![img-3.jpeg](img-3.jpeg)

流处理的数据分析程序，可以实时从事件中提取数据，并产生连续的查询结果。这些查询结果可以更新到数据库中，也可以作为内部的状态被维护。

## Page 7

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Flink概述

## 关键特性

### 1. 同时支持高吞吐、低延迟

高吞吐、低延迟是流处理框架的核心矛盾，Flink为了做到同时支持高吞吐和低延迟的处理能力，在数据的计算、传输、序列化等方面都做了大量优化，从而确保数据处理效率的同时，尽可能的提高吞吐量。

### 2. 丰富的时间语义

时间语义对于流处理应用来说十分重要，基于时间语义的窗口计算是比较常见的流处理方式，Flink支持基于处理时间和事件时间两种时间语义，其中基于事件时间实现的流处理应用，可以保证事件产生的时序性，尽可能避免网络传输或硬件系统的影响出现事件乱序的现象。

### 3. 高度灵活的窗口计算支持

在流处理过程中，数据连续不断产生，无法获取全部数据进行计算，因此，Flink提供了多种类型的窗口计算，用于将无界流切割为多个有界流并划分到不同窗口中进行计算。Flink支持多种类型的窗口计算，并且可以通过制定灵活的窗口计算触发条件，实现复杂的流处理。

### 4. 可靠的容错能力

Flink在执行有状态计算时，基于轻量级分布式快照（Distributed Snapshot）机制，将流处理应用维护的状态制作成快照，每个快照可以视为是一个检查点，检查点可以确保在Flink集群中执行的有状态计算因出现故障而停止执行时，可以通过最新的检查点恢复故障前的状态，除此之外，Flink还支持Exactly-Once的数据一致性语义，确保有状态计算故障恢复后，不会出现数据丢失或者数据重复处理的现象。

### 5. 内存的自主管理

Flink基于JVM（Java Virtual Machine，Java虚拟机）内存运行，JVM内存可分为堆内存（On-Heap Memory）和堆外内存（Off-Heap Memory），默认情况下Flink采用堆内存进行处理，不过堆内存在设计之初是兼顾平衡的，对于处理大规模数据的Flink来说会存在内存溢出（OutOfMemoryError，简写OOM）和垃圾回收（Garbage Collection，简写GC）的问题，为了规避堆内存存在的问题，Flink基于堆外内存实现自主内存管理，所谓堆外内存是指计算机中处于堆内存之外的内存，这些内存可以摆脱JVM的管理，并且可以由计算机的操作系统直接访问。

## Page 8

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink工作原理

$\diamond$ Flink采用Master-Slave架构，运行时由两种类型的进程组成，分别是JobManager和TaskManager。

![img-4.jpeg](img-4.jpeg)

## JobManager

JobManager是作业管理器，负责管理调度整个集群资源和作业，它是真正意义上的“管理者”。

## TaskManager

TaskManager是任务管理器，负责执行任务。

8

## Page 9

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Flink工作原理

![img-5.jpeg](img-5.jpeg)

- 用户编写的程序代码（Program code）以程序数据流（Program Dataflow）的形式传输到优化器（Optimizer）和图生成器（Graph Builder），随后构建数据流图（Dataflow graph）并将其传给客户端（Client）。
- 客户端将数据流图以作业的形式提交给JobManager。
- JobManager将数据流图转换为可执行的执行图（Execution Graph），并分发给可用的TaskManager。TaskManager负责执行任务，多个TaskManager之间以数据流（Data Streams）的形式进行交互。

在Flink中作业和任务是密切相关的概念，一个作业是一个Flink程序的完整实例，通常由一个或多个任务组成，任务是作业的执行单元，每个任务代表一个数据处理操作的实例。这些任务可以并行地执行，从而实现高效的数据处理和计算。

9

## Page 10

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink工作原理

```c
DataStream<string> lines = env.addSource(
new FlinkKafkaConsumer&lt;&gt;(...));
DataStream<event> events = lines.map((line) -&gt; parse(line));
DataStream<statistics> stats = events
.keyBy(event -&gt; event.id)
.timeWindow(Time.seconds(10))
.apply(new MyWindowAggregationFunction());
stats.addSink(new MySink(...));
```

程序数据流

数据流图

执行图

![img-6.jpeg](img-6.jpeg)
parallelism = 1</statistics></event></string>

## Page 11

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Job Manager

![img-7.jpeg](img-7.jpeg)

## JobMaster

JobMaster是作业执行的核心组件，负责协调和管理作业的执行过程。Flink集群中运行的每个作业都对应一个JobMaster。

![img-8.jpeg](img-8.jpeg)

## ResourceManager

ResourceManager是资源管理器，负责Flink集群中资源的分配和管理，所谓资源主要是指TaskManager的Task Slot。

![img-9.jpeg](img-9.jpeg)

## Dispatcher

Dispatcher表示分发器，它负责接收来自客户端的作业提交请求，并将作业分配给JobManager执行。除此之外，Dispatcher还提供了接口供用户查询和监控正在执行的作业。

11

## Page 12

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Task Manager

在Flink中，每个Task Manager可以配置多个Task Slot，Task Slot的数量取决于Task Manager的可用资源，Flink可以将Task Manager的可用资源平均分配到每个Task Slot。

每个Task Slot可以执行特定的子任务（Subtask），子任务是任务的具体执行实例，每个任务基于并行度可以被划分为多个子任务，这些子任务并行地在不同的线程（Threads）上执行，每个子任务都会单独占用任务管理器的一个线程。

![img-10.jpeg](img-10.jpeg)
Source/map()任务的第一个子任务

![img-11.jpeg](img-11.jpeg)
Source/map()任务的第二个子任务

## Page 13

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Task Manager

- Flink允许来自同一个作业的子任务共享Task Slot，即使它们是不同任务的子任务，因此一个Task Slot可以执行多个子任务，这些子任务共享Task Slot的资源

![img-12.jpeg](img-12.jpeg)

![img-13.jpeg](img-13.jpeg)

## Page 14

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Flink部署模式

- Flink是一种非常灵活的处理框架，可以与多种资源管理器集成，包括自身提供的资源管理器和第三方资源管理器，如YARN和Kubernetes。

14

## Page 15

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink部署模式

## Standalone模式

- 在Standalone模式下，Flink使用自带的资源管理器来管理和调度集群资源。这是Flink最基本的部署模式，其中JobManager和TaskManager以Java进程的形式运行。根据部署方式的不同，Standalone模式可进一步细分为伪分布式、完全分布式和高可用完全分布式。

|  **伪分布式**
在单台计算机上运行JobManager和TaskManager。这种部署方式只能利用单台计算机的资源进行计算，并且在计算机出现故障时，整个Flink集群将不可用。 | **完全分布式**
在不同计算机上运行JobManager和TaskManager。相对于伪分布式模式，它可以利用多台计算机的资源进行计算。然而，Flink集群仍然只能有一个JobManager，如果运行JobManager的计算机出现故障，整个集群将不可用。 | **高可用完全分布式**
允许Flink集群拥有多个JobManager。为避免多个JobManager同时提供服务导致的问题，需要借助ZooKeeper的选举机制进行协调。这样可以确保集群中只存在一个提供服务的JobManager，并在出现故障时从其他JobManager中选举一个新的JobManager接管服务。  |
| --- | --- | --- |

15

## Page 16

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink部署模式

## Flink On YARN模式

- Flink On YARN模式使用YARN资源管理器来管理和调度Flink集群的资源。相比于Flink自带的资源管理器，YARN可以根据需求动态分配资源，确保集群资源得到合理分配。因此，该模式在实际生产环境中较为常用。
- YARN（Yet Another Resource Negotiator，另一个资源协调者）是Hadoop提供的一种通用资源管理系统和协调平台，可以为上层应用提供统一的资源管理和调度。YARN的引入为集群在资源利用率、资源统一管理和数据共享等带来了巨大的好处。

16

## Page 17

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink分层API

在Flink分层API中，主要包括SQL、Table API、DataStream API和有状态流处理这四个部分，它们提供了不同的API，以满足不同场景下的数据处理需求。

Flink分层API的顶层是SQL，它允许开发人员使用类似于传统关系型数据库的SQL语句来处理数据，使得熟悉SQL的开发人员能够快速上手并使用Flink进行数据处理。

Table API是Flink提供的高级API，它是以表为中心的声明式编程，用户可以使用类似SQL的声明式语法来处理数据。

DataStream API是 Flink 的核心API，能高效地处理无界数据（流处理）和有界数据（批处理），真正实现了流批一体。

Flink支持状态化的流处理，提供了对应的API来管理和访问状态。

SQL

Table API

DataStream API

有状态流处理

17

## Page 18

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 数据模型

- Flink将输入数据看做是一个不间断、无界的记录序列，一系列记录构成DataStream
- Flink程序使用DataStream类表示无界数据，其为一个可以包含重复项的不可变数据集合

- DataStream的特点
- DataStream中的记录可以是无界的
- DataStream中的记录是不可变的，一旦创建即无法在物理上改变

## Page 19

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 计算模型

- Flink提供丰富的算子对DataStream进行转换
- DataStream经转换后生成新的DataStream
- 一系列的转换操作构成一张有向无环图，即描述计算过程的DAG

## Page 20

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 主要内容

9.1 Flink概述
9.2 DataStream API
9.3 时间和窗口
9.4 状态和容错机制
9.5 Flink CEP

20

## Page 21

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# DataStream编程模型

- Flink程序的构建模块包括流和转换，起始于一个或者多个Source，并终止于一个或者多个Sink。
- Source（数据源）
- Transformation（数据转换）
- Data Sink（数据输出）

![img-14.jpeg](img-14.jpeg)

## Page 22

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.2.1 数据源

数据源模块定义了DataStream API中的数据输入操作

Flink将数据源主要分为两种类型

- 在Flink系统内部已经实现，用户可以直接调用相关方法使用。内置数据源包括文件数据源、Socket数据源和集合数据源
- 第三方数据源包括Kafka、Amazon Kinesis Streams、RabbitMQ、NiFi等，需要使用Connectors（Connectors提供了用于与各种第三方系统进行交互的代码）

22

## Page 23

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

内置数据源

## （1）文件数据源

- Flink支持从文件中读取数据，它会逐行读取数据并将其转换成DataStream返回。可以使用readTextFile(path)方法直接读取文本文件

## （2）Socket数据源

- Flink可以通过调用socketTextStream方法从Socket端口中接入数据，在调用socketTextStream方法时，一般需要提供两个参数，即IP地址（或主机名）和端口

## （3）集合数据源

- Flink可以直接使用fromElements方法将Java程序中集合类转换成DataStream数据集

23

## Page 24

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

第二方数据源

## Flink Project Connectors

- Apache Kafka (source/sink)
- Apache Cassandra (source/sink)
- Amazon DynamoDB (sink)
- Amazon Kinesis Data Streams (source/sink)
- Amazon Kinesis Data Firehose (sink)
- DataGen (source)
- Elasticsearch (sink)
- Opensearch (sink)
- FileSystem (source/sink)
- RabbitMQ (source/sink)
- Google PubSub (source/sink)
- Hybrid Source (source)
- Apache Pulsar (source)
- JDBC (sink)
- MongoDB (source/sink)
- Prometheus (sink)

## Connectors in Apache Bahir

- Apache ActiveMQ (source/sink)
- Apache Flume (sink)
- Redis (sink)
- Akka (sink)
- Netty (source)

## Other Ways to Connect to Flink

Data Enrichment via Async I/O

24

## Page 25

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Kafka数据源

## 首先引入依赖

```html
<dependency>
<groupid>org.apache.flink</groupid>
<artifactid>flink-connector-kafka</artifactid>
<version>3.3.0-1.20</version>
</dependency>
```

## 使用Kafka数据源

```java
KafkaSource<string> source = KafkaSource.<string>builder()
.setBootstrapServers(brokers)
.setTopics("input-topic")
.setGroupId("my-group")
.setStartingOffsets(OffsetsInitializer.earliest())
.setValueOnlyDeserialization(new SimpleStringSchema())
.build();
env.fromSource(source, WatermarkStrategy.noWatermarks(), "Kafka Source");
```

25</string></dependency>

## Page 26

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.2.2 数据转换

- Flink提供了丰富的数据转换算子，主要分为：基于单条记录、基于窗口、合并多条流、拆分单条流。

![img-15.jpeg](img-15.jpeg)

## Page 27

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 1. 基于单条记录的转换算子

## 常用转换算子

|  算子 | 输入输出类型 | 含义  |
| --- | --- | --- |
|  map(func) | DataStream→DataStream | 将一个DataStream中的每个元素传递到函数func中，并将结果返回为一个新的DataStream  |
|  flatMap(func) | DataStream→DataStream | 与map()相似，但每个输入元素都可以映射到0或多个输出结果  |
|  filter(func) | DataStream→DataStream | 筛选出满足函数func的元素，并返回一个新的数据集  |
|  keyBy() | DataStream→KeyedStream | 根据指定的Key将输入的DataStream转换为KeyedStream  |
|  reduce (func) | KeyedStream→DataStream | 将输入的KeyedStream通过传入的用户自定义的函数func滚动地进行数据聚合处理  |
|  聚合 | KeyedStream→DataStream | 根据指定的字段进行聚合操作  |

27

## Page 28

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

keyBy算子

$\diamond$ keyBy操作会将相同Key的数据放置在相同的分区中

![img-16.jpeg](img-16.jpeg)

keyBy算子根据元素的形状对数据进行分组，相同形状的元素被分到了一起，可被后续算子统一处理。

28

## Page 29

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

keyBy算子

$\diamond$ keyBy算子根据指定的Key将输入的DataStream转换为KeyedStream

- KeyedStream用来表示根据指定的Key进行分组的数据流，它是一种特殊的DataStream
- DataStream的各元素随机分布在各个Task Slot中
- KeyedStream的各个元素是按照Key进行分组，然后分配到各个 Task Slot中

$\diamond$ 在KeyedStream上进行任何转换操作以后，该KeyedStream都将转变回DataStream

![img-17.jpeg](img-17.jpeg)

## Page 30

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 聚合算子

聚合算子在KeyedStream数据流上执行滚动聚合，对于同一个 keyedStream，只能调用一次聚合算子。Flink提供了一些内置的、最简单、最基本的聚合算子，主要包括：

- sum(): 在输入流上，对指定的字段做叠加求和的操作;
- min(): 在输入流上，对指定的字段求最小值;
- max(): 在输入流上，对指定的字段求最大值;
- minBy(): 与min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值，而minBy()则会返回包含字段最小值的整条数据。
- maxBy(): 与max()类似，在输入流上针对指定字段求最大值，两者的区别可以参照min()和minBy()的区别。

30

## Page 31

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 2. 物理分区算子

分区是 Flink 进行并行处理的基本单元，Flink 内部的大部分算子都是在分区级别上进行操作。

常见的Flink分区策略包括：

- 随机分区（Shuffle）
- 轮询分区（Round-Robin）
- 重缩放分区（Rescale）
- 广播（Broadcast）
- 全局分区（Global）

![img-18.jpeg](img-18.jpeg)

## Page 32

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

随机分区

$\diamond$ 最简单的重分区方式就是随机分区，通过调用DataStream的shuffle()方法，将上游数据随机分配到下游的并行任务中

![img-19.jpeg](img-19.jpeg)

## Page 33

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 轮询分区

软询也是常见的重分区方式，通过调用DataStream的rebalance()方法，将上游的数据平均分配到下游所有的并行任务中

![img-20.jpeg](img-20.jpeg)

## Page 34

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

重缩放分区

重缩放分区和轮询分区非常相似。当调用rescale()方法时，其实底层也是使用轮询分区算法进行轮询，但是只会将数据轮询发送到下游并行任务的一部分中。

- 重缩放分区的做法是分成“小团体”，发牌人只给自己团体内的所有人轮流发牌。

![img-21.jpeg](img-21.jpeg)

## Page 35

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 广播

这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用DataStream的broadcast()方法，将输入数据复制并发送到下游算子的所有并行任务中去

![img-22.jpeg](img-22.jpeg)

## Page 36

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 全局分区

全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用global()方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。

![img-23.jpeg](img-23.jpeg)

## Page 37

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 算子链

算子链，这是Flink采用的一种称为Operator chain的优化技术，可以在特定条件下减少本地通信的开销。为了满足算子链的要求，必须将两个及以上的操作符（算子）设为相同的并行度，并通过本地转发（local forward）的方式进行连接。

![img-24.jpeg](img-24.jpeg)

## Page 38

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 3.分流

- 所谓的分流就是将一条数据流拆分成多条数据流，就是基于一个DataStream，来得到多个平等的DataStream
- Flink提供了两种分流方式：
- 使用过滤器（Filter）进行分流
- 使用侧输出流（Side Output）进行分流

![img-25.jpeg](img-25.jpeg)

## Page 39

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 使用过滤器介流

## 示例代码

```csharp
DataStreamSource<integer> source = env.fromElements(1,2,3,4,5,6,7,8);
SingleOutputStreamOperator<integer> evenDS = source.filter(value -&gt; value % 2 == 0);
SingleOutputStreamOperator<integer> oddDS = source.filter(value -&gt; value % 2 != 0);
evenDS.print("偶数流");
oddDS.print("奇数流");
```

每次筛选过滤都要保留整个流，然后通过遍历整个流来获取相应的数据，显然很浪费性能。

39</integer></integer></integer>

## Page 40

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

使用侧输出流（Side Output）进行分流

## Flink的侧输出流的作用在于将主数据分割成多个不同的侧输出流

- 侧输出结果流的数据类型不需要与主数据流的类型一致，不同侧输出流的类型也可以不同。

```java
OutputTag<stockprice> stock1Tag =
new OutputTag<("stock_1", types.pojo(stockprice.class))="">;
OutputTag<stockprice> stock2Tag =
new OutputTag<("stock_2", types.pojo(stockprice.class))="">;
SingleOutputStreamOperator<stockprice> processResult
= stockPriceDS.process(new ProcessFunction<stockprice, stockprice="">() {
@Override
public void processElement(StockPrice value, ProcessFunction<stockprice, stockprice="">.Context ctx,
Collector<stockprice> out) throws Exception {
String stockId = value.getStockId();
if ("stock_1".equals(stockId)) {
// 如果ID是stock_1，就放到侧输出流stock_1中
// output方法有两个参数，第1个参数是标签，第2个参数是数据本身
ctx.output(stock1Tag, value);
} else if ("stock_2".equals(stockId)) {
// 如果ID是stock_2，就放到侧输出流stock_2中
ctx.output(stock2Tag, value);
} else {
// 对于其他ID，仍然放在主流中
out.collect(value);
}
});
// 从主流中根据标签获取侧输出流
SideOutputDataStream<stockprice> sideOutputStock1 = processResult.getSideOutput(stock1Tag);
// 从主流中根据标签获取侧输出流
SideOutputDataStream<stockprice> sideOutputStock2 = processResult.getSideOutput(stock2Tag);
// 打印主流
processResult.print("主流");
// 打印侧输出流stock_1
sideOutputStock1.print("侧输出流stock_1");
// 打印侧输出流stock_2
sideOutputStock2.print("侧输出流stock_2");
```

40</stockprice></stockprice></stockprice,></stockprice></stockprice></stockprice></stockprice></stockprice>

## Page 41

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 4.合流

## Flink中合流操作API非常丰富

## 联合(Union)

- 最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”。
- 联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。

![img-26.jpeg](img-26.jpeg)

## Page 42

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# （2）连接（Connect）

- Flink 还提供了另外一种合流操作就是连接。这种操作就是直接把两条流像接线一样对接起来。为了处理更加灵活，连接操作允许流的数据类型不同。但一个数据流中的数据类型是唯一的。
- 连接操作得到的结果并不是一个DataStream，而是一个连接流（ConnectedStream）
- 要想从一个连接流中得到一个新的DataStream，还必须定义个“协同处理”（co-process）转换操作，用来说明对于不同来源、不同类型的数据，怎么分别进行处理转换，得到统一的输出类型。

![img-27.jpeg](img-27.jpeg)

## Page 43

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.2.3 数据输出

1. 输出到文件

- Flink专门提供了一个流式文件系统的连接器FileSink，为批处理和流处理提供了一个统一的Sink，它可以将分区文件写入到Flink支持的文件系统。
- 如果要使用FileSink，需要增加如下依赖：

```xml
<dependency>
<groupid>org.apache.flink</groupid>
<artifactid>flink-connector-files</artifactid>
<version>${flink.version}</version>
</dependency>

## Page 44

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

44

## 2.输出到Kafka

- Kafka Sink提供了一个构建器类来创建 KafkaSink 的实例

```javascript
DataStream<string> stream = ...;
KafkaSink<string> sink = KafkaSink.<string>builder()
.setBootstrapServers(brokers)
.setRecordSerializer(KafkaRecordSerializationSchema.builder()
.setTopic("topic-name")
.setValueSerializationSchema(new SimpleStringSchema())
.build()
)
.setDeliveryGuarantee(DeliveryGuarantee.AT_LEAST_ONCE)
.build();

stream.sinkTo(sink);
```</string></string></string>

## Page 45

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.2.4 DataStream程序开发流程

DataStream程序遵循Flink程序结构，包括Source、Transformation和Sink三个部分，这三个部分共同构成了程序的执行逻辑。然而，仅凭执行逻辑还不足以让DataStream程序正常运行。需要在程序中创建执行环境并添加执行器来触发程序执行。

![img-28.jpeg](img-28.jpeg)

## Page 46

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 执行环境

- 执行环境在DataStream程序中扮演着至关重要的角色，它负责任务调度、资源分配以及程序的执行。
- DataStream API提供了一个StreamExecutionEnvironment类用于创建和配置执行环境。

46

## Page 47

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

执行环境

## 1. 创建执行环境

### （1）createLocalEnvironment()

- 该方法创建的执行环境为本地执行环境，它会在本地计算机创建一个本地环境来执行DataStream程序，通常用于在IDE（集成开发环境）内部执行DataStream程序

```java
StreamExecutionEnvironment localEnvironment =
StreamExecutionEnvironment.createLocalEnvironment();
```

### （2）createRemoteEnvironment()

- 该方法创建的执行环境为远程执行环境，它会将DataStream程序提交到指定的Flink执行，使用该方法时需要依次传入参数host和port，它们分别用于指定Flink Web UI的IP和端口号

```java
StreamExecutionEnvironment remoteEnvironment =
StreamExecutionEnvironment.createRemoteEnvironment("192.168.121.144",8081);
```

47

## Page 48

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

(3) getExecutionEnvironment()

- 该方法创建的执行环境基于运行DataStream程序的环境，如果DataStream程序在IDE运行，那么创建的执行环境为本地执行环境。如果DataStream程序被提交到Flink运行，那么创建的执行环境为远程执行环境

StreamExecutionEnvironment executionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();

![img-29.jpeg](img-29.jpeg)

使用getExecutionEnvironment()方法创建执行环境的方式较为常用。

48

## Page 49

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 执行环境

## 2. 配置执行环境

- (1) setRuntimeMode()

流处理 → DataStream程序默认使用的执行模式，用于实时处理无界流。

批处理 → 专门用于处理有界流的执行模式。

自动模式 → 根据读取数据源的数据是否有界，自行选择DataStream程序使用的执行模式为流处理还是批处理。

```java
executionEnvironment.setRuntimeMode(RuntimeExecutionMode.BATCH); → 批处理
executionEnvironment.setRuntimeMode(RuntimeExecutionMode.AUTOMATIC); → 自动模式
```

## Page 50

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

执行环境

## 2. 配置执行环境

- （1）setParallelism()
- 该方法用于配置DataStream程序的并行度

```txt
executionEnvironment.setParallelism(3);  并行度3
```

不同方式配置并行度的优先级。

![img-30.jpeg](img-30.jpeg)

## Page 51

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 数据类型

DataStream是Flink中用于表示数据集合的类，它是一种抽象的数据结构，实现的DataStream程序其实就是基于这个类的处理，通过在类中使用泛型描述数据集合中每个元素的数据类型。

## 基本数据类型

DataStream支持Java和Scala的**基本数据类型**，如整数、浮点数、字符串等。

## 采用数据类型

- **元组类型**
Flink中的**元组**是一种特殊的数据类型，用于封装不同类型的元素。

在Java中，**POJO** (Plain Ordinary Java Object) 是这样的Java类：(1) 有一个无参的默认构造器；(2) 所有的字段要么是public的，要么有一个默认的getter和setter。

## POJO类型

**POJO**是一个符合特定条件的Java类，它用于表示具有多个属性的数据结构。

51

## Page 52

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

数据类型

## Java DataStream API使用的流数据类型

- 对于Java API，Flink定义了自己的Tuple1到Tuple25类型来表示元组类型。

```java
Tuple2<string, integer=""> person = new Tuple2&lt;&gt;("王老五", 35);
// 索引基于0
String name = person.f0;
Integer age = person.f1;
```

## Scala DataStream API使用的流数据类型

- 对于元组，使用Scala自己的Tuple类型就好。
- 对于对象类型，使用case class（相当于Java中的JavaBean）

```txt
val person = ("王老五", 35)
// 索引基于1
val name = person._1
val age = person._2
```

52</string,>

## Page 53

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

完整示例

```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.api.common.functions.FilterFunction;

public class Example {
public static void main(String[] args) throws Exception {
final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

DataStream<person> flintstones = env.fromData(
new Person("Fred", 35),
new Person("Wilma", 35),
new Person("Pebbles", 2));

DataStream<person> adults = flintstones.filter(new FilterFunction<person>() {
@Override
public boolean filter(Person person) throws Exception {
return person.age &gt;= 18;
}
});
adults.print();
env.execute();
}
}
```

```java
public static class Person {
public String name;
public Integer age;
public Person() {}
public Person(String name, Integer age) {
this.name = name;
this.age = age;
}
public String toString() {
return this.name.toString() + ": age " + this.age.toString();
}
}
}
}
```

53</person></person></person>

## Page 54

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 主要内容

9.1 Flink概述
9.2 DataStream API
9.3 时间和窗口
9.4 状态和容错机制
9.5 Flink CEP

54

## Page 55

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

时间概念

# Flink根据时间产生的位置将数据的时间属性分为事件时间和处理时间两种类型。

![img-31.jpeg](img-31.jpeg)

## 事件时间

使用基于事件时间的窗口算子处理无界流时，其处理结果更加符合实际的业务逻辑，并且处理结果也更加精准，所以在实际应用中也是较为常用的。

![img-32.jpeg](img-32.jpeg)

## 处理时间

处理时间并不会通过数据产生时嵌入的时间属性判断数据产生的先后顺序，可以看作是数据一旦传输到窗口算子就立即进行处理，所以基于处理时间的窗口算子对无界流进行处理时，效率会更高。

55

## Page 56

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 窗口概念

将无界流划分为多个有界流，并针对每个有界流进行处理，此时的处理结果是针对每个有界流内的所有数据，从而减少了输出处理结果的次数，此过程中产生的每个有界流都视为一个单独的窗口，对于有界流的处理就视为窗口操作。

56

## Page 57

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

窗口概念

# Keyed Window VS Non-Keyed Window

- Keyed Window：一种按特定键（Key）对数据进行分组的窗口机制，作用于KeyedStream
- Non-Keyed Window：直接调用windowAll()函数执行窗口计算

![img-33.jpeg](img-33.jpeg)

![img-34.jpeg](img-34.jpeg)

## Page 58

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

窗口概念

## 数据流类型的转换过程

- 当对一个数据流执行keyBy()函数时，它会从DataStream类型转变为KeyedStream类型；然后，在KeyedStream类型的数据流上执行windows()函数时，数据流又会转变为WindowedStream类型；最后，在WindowedStream类型的数据流上执行reduce()等函数时，数据流又会转变成DataStream类型。当对一个数据流执行windows()函数时，它会从DataStream类型转变为AllWindowedStream类型，在AllWindowedStream类型的数据流上执行reduce()等函数时，数据流又会转变成DataStream类型。

![img-35.jpeg](img-35.jpeg)

## Page 59

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

窗口计算

## Flink的窗口计算包含两个必须的操作：

- 使用窗口分配器（WindowAssigner）将数据流中的元素分配到对应的窗口
- 当满足窗口触发条件后，对窗口内的数据使用窗口计算函数（Window Function）进行处理。

## KeyedStream的窗口计算

```txt
dataStream.keyBy(...) //是分组数据流
.window(...) //指定窗口分配器类型
[.trigger(...) //指定触发器类型（可选）
[.evictor(...) //指定驱逐器或者不指定（可选）
[.allowedLateness()] //指定是否延迟处理数据（可选）
.reduce/aggregate/apply() //指定窗口计算函数
```

## Non-KeyedStream的窗口计算

```txt
dataStream.windowAll(...) //指定窗口分配器类型
[.trigger(...) //指定触发器类型（可选）
[.evictor(...) //指定驱逐器或者不指定（可选）
[.allowedLateness()] //指定是否延迟处理数据（可选）
.reduce/aggregate/apply() //指定窗口计算函数
```

59

## Page 60

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.1 窗口分配器

## 1. 滚动窗口

- 滚动窗口是根据固定时间或大小对数据流进行切分，且窗口和窗口之间的元素不会重叠
- DataStream API提供了两种滚动窗口类型，即基于事件时间的滚动窗口和基于处理时间的滚动窗口，二者对应的窗口分配器分别为 TumblingEventTimeWindows和TumblingProcessingTimeWindows。
- 窗口的长度可以用org.apache.flink.streaming.api.windowing.time.Time中的seconds、minutes、hours和days来设置。

![img-36.jpeg](img-36.jpeg)

## Page 61

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.1 窗口分配器

## 2. 滑动窗口

- 对于滑动窗口而言，也是采用固定相同间隔分配窗口，只不过每个窗口之间有重叠。
- 对应的窗口分配器分别为SlidingEventTimeWindows和SlidingProcessingTimeWindows
- 滑动窗口有两个参数，分别是窗口大小（Window Size）和滑动步长（Slide），后者决定了窗口每次向前滑动的距离。
- SlidingEventTimeWindows

![img-37.jpeg](img-37.jpeg)

## Page 62

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.1 窗口分配器

## 3.会话窗口

- 会话窗口根据会话间隙（Session Gap）切分不同的窗口，当一个窗口在大于会话间隙的时间内没有接收到新数据时，窗口将关闭。
- 在这种模式下，窗口的长度是可变的，每个窗口的开始和结束时间并不是确定的。
- 对应的窗口分配器分别为EventTimeSessionWindows和ProcessingTimeSessionWindows
- 可以设置定长的会话间隙，也可以使用SessionWindowTimeGapExtractor动态地确定会话间隙的长度。

![img-38.jpeg](img-38.jpeg)

## Page 63

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.1 窗口分配器

## 4. 全局窗口

- 全局窗口会把具有相同key的所有元素都分配到相同的单个全局窗口内，这种窗口机制只在采用自定义触发器时才有意义。

```c
DataStream<t> dataStream = ...;
```

```c
dataStream
.keyBy(...)
window(GlobalWindows.create())
.<window function="">(...)
```

![img-39.jpeg](img-39.jpeg)</window>

## Page 64

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.2 窗口计算函数

在Flink的窗口计算程序中，在确定了窗口分配器以后，接下来就要确定窗口计算函数，从而完成对窗口内数据集的计算。

Flink提供了三种类型的窗口计算函数，分别是**ReduceFunction、AggregateFunction**和**ProcessWindowFunction**。

- **ReduceFunction** 和 **AggregateFunction** 属于增量聚合函数
- 增量聚合函数是基于中间状态计算结果的，窗口中只维护中间状态结果值，不需要缓存原始的数据
- **ProcessWindowFunction** 则属于全量聚合函数
- 全量窗口函数在窗口触发时对所有的原始数据进行汇总计算，因此相对性能会较差，但能保存窗口中的状态数据和窗口元数据

64

## Page 65

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.2 窗口计算函数

1. ReduceFunction

- ReduceFunction定义了对输入的两个相同类型的数据元素按照指定的计算方法进行聚合计算，然后输出类型相同的一个结果元素。

```cpp
DataStream<tuple2<string, long="">&gt; input = ...;
input
.keyBy(<key selector="">)
.window(<window assigner="">)
.reduce(new ReduceFunction<tuple2<string, long="">&gt;() {
public Tuple2<string, long=""> reduce(Tuple2<string, long=""> v1, Tuple2<string, long=""> v2) {
return new Tuple2&lt;&gt;(v1.f0, v1.f1 + v2.f1);
}
});
```

65</string,></string,></string,></string,></key></string,></type></tuple2<string,>

## Page 66

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.2 窗口计算函数

## 2. AggregateFunction

- ReduceFunction可以解决大多数聚合问题，但是，也存在一个限制，就是聚合状态的类型、输出结果的类型都必须和输入数据类型一样。AggregateFunction可以突破ReduceFunction的这个限制，可以定义更加灵活的窗口聚合操作。
- AggregateFunction比ReduceFunction更加通用，它定义了4个需要复写的方法，其中，createAccumulator()用于创建一个累加器，add()定义了数据的添加逻辑，getResult()定义了累加器计算的结果，merge()定义了累加器合并的逻辑。

66

## Page 67

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.2 窗口计算函数

## 2. AggregateFunction

- AggregateFunction需定义三种数据类型：输入类型（IN）、累加器类型（ACC）和输出类型（OUT）

```java
private static class AverageAggregate
implements AggregateFunction<tuple2<string, long="">, Tuple2<long, long="">, Double&gt; {
@Override
public Tuple2<long, long=""> createAccumulator() {
return new Tuple2&lt;&gt;(OL, OL);
}

@Override
public Tuple2<long, long=""> add(Tuple2<string, long=""> value, Tuple2<long, long=""> accumulator) {
return new Tuple2&lt;&gt;(accumulator.f0 + value.f1, accumulator.f1 + 1L);
}
DataStream<tuple2<string, long="">&gt; input = ...;

@Override
public Double getResult(Tuple2<long, long=""> accumulator) {
return ((double) accumulator.f0) / accumulator.f1;
}

input
.keyBy(<key selector="">)
.window(<window assigner="">)
.aggregate(new AverageAggregate());
}

@Override
public Tuple2<long, long=""> merge(Tuple2<long, long=""> a, Tuple2<long, long=""> b) {
return new Tuple2&lt;&gt;(a.f0 + b.f0, a.f1 + b.f1);
}
}</long,></long,></long,></long,></window></long></long,></long,></string,></long,></long,></long,></long,></double></long,></long,></long,></double>

## Page 68

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.2 窗口计算函数

## 3. ProcessWindowFunction

- ReduceFunction和AggregateFunction虽然已经满足绝大多数场景的需求，但是，在某些情况下统计更复杂的指标可能需要依赖于窗口中所有的数据元素，或需要操作窗口中的状态数据和窗口元数据，这时就需要使用到 ProcessWindowFunction，因为它能够更加灵活地支持基于窗口全部数据元素的结果计算。
- ProcessWindowFunction 会获取一个包含窗口内所有元素的 *Iterable 对象*，以及一个提供时间信息和状态访问的 *Context 对象*，这使其比其他窗口函数更具灵活性
- 但代价是资源消耗更高，因为元素无法进行增量聚合，而是需要在内部缓冲，直到窗口被认为准备好处理为止。

68

## Page 69

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.2 窗口计算函数

# 3. ProcessWindowFunction

DataStream<tuple2<string, long="">&gt; input = ...;

input
.keyBy(t -&gt; t.f0)
.window(TumblingEventTimeWindows.of(Duration.ofMinutes($)))
.process(new MyProcessWindowFunction());

/* ... */

public class MyProcessWindowFunction
extends ProcessWindowFunction<tuple2<string, long="">, String, String, TimeWindow&gt; {
@Override
public void process(String key, Context context, Iterable<tuple2<string, long="">&gt; input, Collector<string> out) {
long count = 0;
for (Tuple2<string, long=""> in: input) {
count++;
}
out.collect("Window: " + context.window() + "count: " + count);
}
}

public abstract class ProcessWindowFunction<in, out,="" extends="" key,="" int,="" windows=""> implements Function
```</in,></string,></tuple2<string,></tuple2<string,></string></tuple2<string,></string,>

## Page 70

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.2 窗口计算函数

## 4. 增量聚合函数和全量聚合函数的结合使用

- 使用增量聚合函数（ReduceFunction和AggregateFunction）时，系统会每到达一条数据就执行一次计算，并且只保留中间结算结果，因此，占用空间小，但是，它不够灵活，无法获得一些关于窗口的元数据信息（比如窗口的开始时间、结束时间、窗口内包含的元素等）。
- 使用全量聚合函数ProcessWindowFunction时，可以获得关于窗口的元数据信息，但是，系统会保存每一条到达的数据，积攒一段时间以后统一执行一次计算，这样会造成数据的堆积，占用空间大。
- 在实际应用中，我们往往希望兼具二者的优点，把它们结合在一起使用。
- 在Flink中，全量聚合函数ProcessWindowFunction可以和增量聚合函数（ReduceFunction或者AggregateFunction）结合使用。当窗口关闭时，ProcessWindowFunction会获得聚合结果，这样就可以对窗口中的元素进行增量计算，并且同时能够通过ProcessWindowFunction获得窗口的一些元数据信息。

70

## Page 71

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.2 窗口计算函数

## 4.增量聚合函数和全量聚合函数的结合使用

```cpp
DataStream<sensorreading> input = ...;
input
.keyBy(<key selector="">)
.window(<window assigner="">)
.reduce(new MyReduceFunction(), new MyProcessWindowFunction());
```

// Function definitions

```cpp
private static class MyReduceFunction implements ReduceFunction<sensorreading> {
public SensorReading reduce(SensorReading r1, SensorReading r2) {
return r1.value() &gt; r2.value() ? r2 : r1;
}
}

private static class MyProcessWindowFunction
extends ProcessWindowFunction<sensorreading, steps="" tuple2<long,="" sensorreading="">, String, TimeWindow &gt; {
public void process(String key,
Context context,
Iterable<sensorreading> minReadings,
Collector<tuple2<long,="" sensorreading="">&gt; out) {
SensorReading min = minReadings.iterator().next();
out.collect(new Tuple2<long, sensorreading="">(context.window().getStart(), min));
}
}
```

71</long,></tuple2<long,></sensorreading></sensorreading></t

## Page 72

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.3 触发器

窗口的计算触发依赖于窗口触发器，每种类型的窗口都有对应的窗口触发机制，都有一个默认的窗口触发器，触发器的作用就是去控制什么时候来触发计算。Flink内部定义多种触发器，每种触发器对应于不同的窗口分配器。

## 常见的触发器如下：

- EventTimeTrigger: 通过对比EventTime和窗口的Endtime确定是否触发窗口计算，如果EventTime大于EndTime则触发，否则不触发，窗口将继续等待。
- ProcessTimeTrigger: 通过对比ProcessTime和窗口的EndTime确定是否触发窗口，如果ProcessTime大于EndTime则触发计算，否则窗口继续等待。
- ContinuousEventTimeTrigger: 根据间隔时间周期性触发窗口或者窗口的结束时间小于当前EndTime触发窗口计算。
- ContinuousProcessingTimeTrigger: 根据间隔时间周期性触发窗口或者窗口的结束时间小于当前ProcessTime触发窗口计算。
- CountTrigger: 根据接入数据量是否超过设定的阈值判断是否触发窗口计算。
- DeltaTrigger: 根据接入数据计算出来的Delta指标是否超过指定的Threshold去判断是否触发窗口计算。
- PurgingTrigger: 可以将任意触发器作为参数转换为Purge类型的触发器，计算完成后数据将被清理。
- NeverTrigger: 任何时候都不触发窗口计算。

72

## Page 73

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.4 驱逐器

- Flink窗口模型还允许在窗口分配器和触发器之外指定一个驱逐器（Evictor）。
- 驱逐器是Flink窗口机制中一个可选的组件，其主要作用是对进入窗口函数前后的数据进行驱逐处理。

- Flink内部实现了三种驱逐器：
- CountEvictor: 保持在窗口中具有固定数量的记录，将超过指定大小的数据在窗口计算之前删除；
- DeltaEvictor: 使用DeltaFunction和一个阈值，来计算窗口缓冲区中的最后一个元素与其余每个元素之间的差值，并删除差值大于或等于阈值的元素；
- TimeEvictor: 以毫秒为单位的时间间隔（interval）作为参数，对于给定的窗口，找到元素中的最大的时间戳 max_ts，并删除时间戳小于max_ts - interval的所有元素。

73

## Page 74

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.4 驱逐器

驱逐器能够在触发器触发之后，窗口函数使用之前或之后从窗口中清除元素。在使用窗口函数之前被逐出的元素将不被处理

- 默认情况下，所有内置的驱逐器在窗口函数之前使用。

和触发器一样，用户也可以通过实现Evictor接口完成自定义的驱逐器。自定义驱逐器时，需要复写Evictor接口的两个方法：

- evictBefore()方法定义数据在进入窗口函数计算之前执行驱逐操作的逻辑
- evictAfter()方法定义数据在进入窗口函数计算之后执行驱逐操作的逻辑。

74

## Page 75

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.5 水位线（WaterMark）

在实际状态下，由于网络传输延迟或分布式系统影响等原因，往往会出现数据乱序的现象。此时，不能简单的通过数据自带的时间戳来衡量事件时间的进展，而需要一种特殊的标记来衡量事件时间的进展，在Flink中，这种用来衡量事件时间进展的标记，就被称作水位线

75

## Page 76

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.5 水位线（WaterMark）

水位线可以看作是一个特殊的记录被插入到无界流中，其主要内容就是一个时间戳，用来指定当前的事件时间，水位线插入到无界流的位置，是在某个数据到来之后，这样就可以从这个数据中提取时间戳，作为当前水位线的时间戳。

![img-40.jpeg](img-40.jpeg)

在实际状态中，无界流的数据会出现乱序现象，此时如果在每条数据到来之后都在其后面插入一个水位线的话，水位线所衡量事件时间的进展便会出现回退的现象。

![img-41.jpeg](img-41.jpeg)

## Page 77

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.5 水位线（WaterMark）

- 每个并行子任务通常独立生成其水印
- 某些算子会消费多个输入流，此类算子的当前事件时间是其所有输入流事件时间的最小值

![img-42.jpeg](img-42.jpeg)

## Page 78

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.5 水位线（WaterMark）

- Flink提供了单调递增的水位线生成策略，该策略向无界流插入水位线时，会先判断当前插入水位线的时间戳是否比之前水位线的时间戳大，否则便不会向无界流中插入水位线。

![img-43.jpeg](img-43.jpeg)

通过单调递增的水位线生成策略会向无界流插入大量的水位线，影响处理的效率，为此，Flink提供了周期性生成水位线的策略，该策略根据系统时间周期性的向无界流插入水位线，该水位线的时间戳就是之前到来的所有数据的最大时间戳。

![img-44.jpeg](img-44.jpeg)

## Page 79

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 9.3.5 水位线（WaterMark）

## 水位线决定了窗口何时关闭

- 例如，当时间戳为7秒的数据到来之后，会向无界流中插入一个水位线W(7)，此时若某个窗口的结束时间为7秒，那么符合水位线的时间戳大于等于窗口结束时间的条件，此时该窗口便会关闭，那么后续到来的时间戳为6秒的数据便不会分配到该窗口内进行计算，导致计算结果不准确，时间戳为6秒的数据就是由于数据乱序延迟到达的数据。为了使窗口能够正确收集到延迟到达的数据，可以等上2秒再关闭窗口就可以了，在具体实现上就是数据的时间戳减去2秒作为水位线的时间戳。

![img-45.jpeg](img-45.jpeg)

## Page 80

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.5 水位线（WaterMark）

在DataStream程序中，可以调用DataStream对象的assignTimestampsAndWatermarks()方法使用水位线，该方法包含一个参数WatermarkStrategy，该参数是一个接口，用于在使用水位线时指定时间戳分配器和水位线生成器。

- 时间戳分配器
- 通过实现WatermarkStrategy接口的withTimestampAssigner()方法指定时间戳分配器，其作用是从数据中提取时间戳，再将时间戳作为事件时间分配给数据

- 水位线生成器
- 可以直接实现WatermarkStrategy接口的forBoundedOutOfOrderness()方法，使用Flink内置的水位线生成器，该水位线生成器默认使用单调递增的水位线生成策略，若想要使用周期性水位线生成策略，则需要通过执行环境进行配置。

80

## Page 81

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

81

# 9.3.5 水位线（WaterMark）

## 使用水位线的语法格式

```txt
dataStream.assignTimestampsAndWatermarks(
WatermarkStrategy
.<inputdatatype>forBoundedOutOfOrderness(time)
.withTimestampAssigner(timeAttribute)
)
```

- 周期性水位线生成策略的本质是在单调递增的水位线生成策略增加了一个周期性。
- 通过执行环境指定周期性插入水位线的时间即可

```txt
executionEnvironment.getConfig().setAutoWatermarkInterval(5000L)</inputdatatype>

## Page 82

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.5 水位线（WaterMark）

延迟数据处理

- 默认情况下，当水位线超过窗口结束时间之后，再有之前的数据到达时，这些数据会被删除。
allowedLateness就是针对事件时间而言，对于水位线超过窗口结束时间之后，还允许有一段时间（也是以事件时间来衡量）来等待之前的数据到达，以便再次处理这些数据。
- 默认情况下，如果没有在程序中指定allowedLateness，那么它的默认值是0，即对于水位线超过窗口结束时间之后，如果还有属于此窗口的数据到达时，这些数据就会被删除掉。

82

## Page 83

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

9.3.5 水位线（WaterMark）

延迟数据处理

- 设置了allowedLateness以后，只有水位线大于“窗口结束时间+allowedLateness”时，窗口才会被销毁。
- 通常情况下，用户虽然希望对迟到的数据进行窗口计算，但并不想将结果混入正常的计算流程中，而是想将延迟数据和结果保存到数据库中，便于后期对延时数据进行分析。对于这种情况，就需要借助于“侧输出”（Side Output）来处理，通过使用sideOutputLateData(OutputTag)来标记迟到数据计算的结果，然后使用getSideOutput(lateOutputTag)从窗口中获取lateOutputTag标签对应的数据，之后转成独立的DataStream数据集进行处理。

83

## Page 84

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 主要内容

9.1 Flink概述
9.2 DataStream API
9.3 时间和窗口
9.4 状态和容错机制
9.5 Flink CEP

84

## Page 85

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

概述

在有状态流处理中，状态是一种重要的机制，它可以帮助在处理数据时存储、维护和更新中间结果，从而完成更加复杂的计算任务。但同时，状态的管理也是有状态流处理中不可避免的问题。

- 如果状态管理不当，可能会导致计算结果不准确。
- 例如，如果某个任务的状态因为节点故障或者任务异常而丢失，那么重启该任务时，状态需要进行恢复。

Flink提供了完善的容错机制，保证了状态的可靠性和一致性

- 通过使用Flink的容错机制，可以避免状态丢失导致计算结果不准确的问题，从而确保有状态流处理应用的正确性。

85

## Page 86

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 状态概述

- 状态由Flink集群运行架构中TaskManager的任务进行维护，默认存储在内存中，可以将状态理解为内存中的一个变量，它存储着有状态流处理应用对历史数据的处理结果，当新的数据进入有状态流处理应用时，可以利用状态中存储的历史数据处理结果，结合新的数据一起进行处理，并根据处理结果更新状态。

![img-46.jpeg](img-46.jpeg)

## Page 87

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 状态概述

- Flink有两种基本类型的状态：托管状态（Managed State）和原生状态（Raw State）。
- 托管状态是由Flink管理的，Flink帮忙存储、恢复和优化
- 托管状态又包含两种类型的状态：算子状态（operator state）和键控状态（keyed state）
- 原生状态是开发者自己管理的，需要自己序列化，一般很少使用。

87

## Page 88

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 算子状态

## 算子状态的作用范围限定为算子任务

- 这意味着由同一并行任务所处理的所有数据都可以访问到相同的状态，状态对于同一任务而言是共享的。算子状态不能由相同或不同算子的另一个任务访问。

![img-47.jpeg](img-47.jpeg)

## Page 89

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 键控状态

## 键控状态是根据输入数据流中定义的键（Key）来维护和访问的

- Flink为每个键值维护一个状态实例，并将具有相同键的所有数据，部分区到同一个算子任务中，这个任务会维护和处理这个键对应的状态。当任务处理一条数据时，它会自动将状态的访问范围限定为当前数据的键。因此，具有相同键的所有数据都会访问相同的状态。键控状态很类似于一个分布式的键值对映射数据结构，只能用于KeyedStream

![img-48.jpeg](img-48.jpeg)

## Page 90

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 状态概述

无论是键控状态还是算子状态，Flink的状态都是基于本地的，即每个算子子任务维护着这个算子子任务对应的状态存储，算子子任务之间的状态不能相互访问。

|   | 键控状态 | 算子状态  |
| --- | --- | --- |
|  适用算子类型 | 只适用于KeyedStream上的算子 | 可以用于所有算子  |
|  状态分配 | 每个Key对应一个状态 | 一个算子子任务对应一个状态  |
|  创建和访问方式 | 重写Rich Function，通过里面的RuntimeContext访问 | 实现CheckpointedFunction等接口  |
|  横向扩展 | 状态随着Key自动在多个算子子任务上迁移 | 有多种状态重新分配的方式  |
|  支持的数据结构 | ValueState、ListState、MapState、ReducingState、AggregatingState等 | ListState、BroadcastState等  |

90

## Page 91

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 状态概述

## 状态数据结构

- ValueState: 类型为T的单值状态
- 可以使用update(T)方法进行更新，并通过value()方法获取状态值。

- ListState: 存储列表类型的状态，它提供了以下方法：
- get()方法：获取值
- add(IN value)和addAll(List values)方法：更新值
- update(List values)方法：用新列表替换原来的列表
- clear()方法：清空列表，列表还存在，但是没有元素

- MapState: 用于维护Map类型的状态，常用的方法如下：
- get()方法：获取值
- put()和putAll()方法：更新值
- remove()方法：删除某个key
- contains()方法：判断是否存在某个key
- isEmpty()方法：判断是否为空

91

## Page 92

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 状态概述

## 状态数据结构

- ReducingState: 和ReduceFunction配合使用的，它主要提供了两个方法：
- get()方法：获取状态的值
- add()方法：添加一个元素，触发ReduceFunction计算一次，合并到一个单一的状态值

- AggregatingState: 聚合的类型可以是不同的元素类型，输入和输出的类型可以不同
- 使用add()方法添加元素，并使用AggregateFunction函数计算聚合结果。

92

## Page 93

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 状态编程示例

```java
public class CountWindowAverage extends RichFlatMapFunction<tuple2<long, long="">, Tuple2<long, long="">&gt; {
//**
* The valueState handle. The first field is the count, the second field a running sum.
*/
private transient valueState<tuple2<long, long="">&gt; sum;

@Override
public void flatMap(Tuple2<long, long=""> input, Collector<tuple2<long, long="">&gt; out) throws Exception {
// access the state value
Tuple2<long, long=""> currentSum = sum.value();

// update the count
currentSum.f0 += 1; // this can be used in a streaming program like this (assuming we have a StreamExecutionEnvironment env)
env.fromElements(Tuple2.of(1L, 3L), Tuple2.of(1L, 5L), Tuple2.of(1L, 7L), Tuple2.of(1L, 4L), Tuple2.of(1L, 2L))
.keyBy(value -&gt; value.f0)
.flatMap(new CountWindowAverage())
.print();

// update the state
sum.update(currentSum); // the printed output will be (1,4) and (1,5)

// if the count reaches 2, emit the average and clear the state
if (currentSum.f0 &gt;= 2) {
out.collect(new Tuple2&lt;&gt;(input.f0, currentSum.f1 / currentSum.f0));
sum.clear();
}
}

@Override
public void open(OpenContext ctx) {
ValueStateDescriptor<tuple2<long, long="">&gt; descriptor = new ValueStateDescriptor&lt;&gt;(
"average", // the state name
TypeInformation.of(new TypeHint<tuple2<long, long="">&gt;() {}), // type information
Tuple2.of(0L, 0L)); // default value of the state, if nothing was set
sum = getRuntimeContext().getState(descriptor);
}
}</tuple2<long,></tuple2<long,></tuple2<long,></tuple2<long,></tuple2<long,></long,></tuple2<long,></td></tr></table></long,></long,></tuple2<long,></td></tr>

## Page 94

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Checkpoint

- Checkpoint是一种容错恢复机制，这种机制通过Chandy-Lamport算法为有状态流处理应用中每个任务所维护的状态生成Snapshot（快照），并且将Snapshot发送到存储介质。
- Flink 使用轻量级异步快照机制生成快照，该机制借鉴了分布式快照的标准 Chandy-Lamport 算法，并专门针对 Flink 的执行模型进行了定制。

94

## Page 95

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Checkpoint

- Chandy-Lamport算法使用了一种特殊的元素用于控制 Snapshot的生成，即**Checkpoint Barrier**。在有状态流处理应用执行过程中，JobManager会创建**Checkpoint Coordinator**，**Checkpoint Coordinator**会根据指定的时间间隔定期在无界流的固定位置插入带有**Checkpoint Id**的**Checkpoint Barrier**。**Checkpoint Barrier**随着无界流在有状态流处理应用的各个任务之间传递，每当任务接收到**Checkpoint Barrier**时，便将其维护的状态生成为**Snapshot**，每个**Snapshot**都保存了有状态流处理应用每个任务的完整状态

![img-49.jpeg](img-49.jpeg)

## Page 96

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Checkpoint

当有状态流处理应用的某一任务的并行度大于1时，该任务会等待所有具有相同Checkpoint Id的Checkpoint Barrier全部到达后，才为该任务维护的状态生成Snapshot，并发送到存储介质，这个等待的过程，称之为Barrier对齐。

![img-50.jpeg](img-50.jpeg)

## Page 97

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Checkpoint

## Checkpoint支持的语义

- Exactly Once (精确一次)
- 确保无界流中每条数据对于有状态流处理应用的每个状态只影响一次，即无界流中的数据不会出现重复处理或者丢失的现象

- At least Once (至少一次)
- 确保无界流中每条数据对于有状态流处理应用的每个状态至少影响一次，即无界流中的数据会出现重复处理的现象，但不会出现数据丢失的现象，出现重复处理的现象的原因在于，Checkpoint使用At least Once语义时，没有分界线对齐的过程。

97

## Page 98

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Checkpoint

## Checkpoint VS Savepoint

- Checkpoint是由Flink自动管理的，可以定期为状态生成Snapshot，在有状态流处理应用发生故障之后自动读取对应的Snapshot进行恢复
- Savepoint为状态生成Snapshot的过程，必须由用户手动触发，并且有状态流处理应用发生故障之后，如果想要通过Savepoint恢复有状态流处理应用的执行，同样也需要用户手动触发

98

## Page 99

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

State Backend

# State Backend用于指定状态和Snapshot的存储介质

- HashMapStateBackend
- State Backend默认使用的类型，它将状态存储在内存中，这样可以获得更快的读写速度，使计算性能达到最佳，但代价是内存的占用
- EmbeddedRocksDBStateBackend
- 通过RocksDB存储状态，RocksDB是一种高性能的嵌入式键值对数据库，它会将状态存储在对应任务所运行的TaskManager本地磁盘中

这两种类型的State Backend都可以通过内存或文件系统来持久化Snapshot.

99

## Page 100

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 故障恢复

当有状态流处理应用发生故障时，Flink会通过Checkpoint重新启动每个任务，从而恢复其正常执行。

- Flink为了重启和恢复有状态流处理应用的正常执行，提供了不同的重启策略和恢复策略
- 重启策略
- 固定延迟重启策略
- 故障率重启策略
- 无重启策略
- 恢复策略
- 全局恢复策略：指恢复有状态流处理应用所有任务的正常执行
- 局部恢复策略：是指恢复有状态流处理应用中与故障相关的部分任务，而不是恢复所有任务。

100

## Page 101

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 主要内容

9.1 Flink概述
9.2 DataStream API
9.3 时间和窗口
9.4 状态和容错机制
9.5 Flink CEP

101

## Page 102

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# Flink CEP基本概述

Flink CEP是Flink实现的一个用于复杂事件处理的库（Library），它可以根据用户定义的匹配规则检测数据流中的复杂事件，然后对满足匹配规则的复杂事件进行处理，并输出处理结果。

![img-51.jpeg](img-51.jpeg)

## Page 103

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

Flink CEP基本概述

# 应用场景

![img-52.jpeg](img-52.jpeg)

![img-53.jpeg](img-53.jpeg)

![img-54.jpeg](img-54.jpeg)

## 风险控制

通过预定义的匹配规则实时检测用户的异常行为。当用户的行为符合匹配规则时，系统判定其出现异常行为。

## 实时营销

通过预定义的匹配规则实时跟踪用户的行为轨迹。当用户的行为轨迹符合匹配规则时，系统实时向用户发送相应策略的推广。

## 运维监控

通过预定义的匹配规则实时监控服务器的指标，如CPU、网络IO等。当服务器的指标符合匹配规则时，系统实时产生相应的警告。

103

## Page 104

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

模式

## 模式

在Flink CEP中，用户定义的匹配规则称之为模式（Pattern）。模式内部主要包含个体模式（Individual Pattern）和组合模式（Combining Pattern）两部分内容。

![img-55.jpeg](img-55.jpeg)

## Page 105

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式

## 1 个体模式

### 单例模式

单例模式仅检测数据流中的单个事件。

### 循环模式

循环模式则可检测并组合数据流中连续出现的具有相同特征的多个事件。循环模式默认的连续性（Contiguity）规则为宽松连续性。

复杂事件由多个单独的事件组合而成。在Flink CEP中，为了识别数据流中的复杂事件，需要为每个单独事件设定匹配规则，这些规则被称为个体模式。

105

## Page 106

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

模式

## 1 个体模式

单例模式和循环模式检测数据流的效果。

![img-56.jpeg](img-56.jpeg)

![img-57.jpeg](img-57.jpeg)

![img-58.jpeg](img-58.jpeg)

Flink CEP是如何确保检测到的事件就是想要获取的事件呢？

106

## Page 107

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

様式

## 1 个体模式

这时就需要为个体模式定义条件（Conditions）。条件可以被看作是数据流中事件的选取规则，它构成了个体模式事件检测的核心。Flink CEP 会根据用户定义的条件筛选数据流中的事件，以决定是否选取当前事件。

### 1. 简单条件

简单条件基于数据流中的当前事件进行判断。如果当前事件满足设定的选取规则，那么就会被选取。

### 3. 组合条件

组合条件将多个简单条件或迭代条件结合成一个新的条件。如果当前事件满足这个新设定的条件，就会被选取。

![img-59.jpeg](img-59.jpeg)

### 2. 迭代条件

迭代条件基于数据流中的当前事件和历史事件进行判断。如果这些事件满足设定的选取规则，当前事件就会被选取。

### 4. 终止条件

终止条件主要应用于循环模式的个体模式。当连续出现同样特征的多个事件时，如果遇到某个特定的事件，那么检测将会终止。

![img-60.jpeg](img-60.jpeg)

## Page 108

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式

## 2 组合模式

### 组合模式

将预先定义好的个体模式，按照设定的连续性规则有序连接，可以构成完整的模式序列（Pattern Sequence），这个过程被称为组合模式。Flink CEP通过组合模式能够在数据流中识别复杂事件。Flink CEP支持三种连续性规则，即严格连续性（Strict Contiguity）、宽松连续性（Relaxed Contiguity）和非确定性放松连续性（Non-Deterministic Relaxed Contiguity）。

![img-61.jpeg](img-61.jpeg)

## Page 109

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

模式

## 2 组合模式

### (1) 严格连续性

严格连续性是组合模式的默认连续性规则，它要求组合模式中不同个体模式检测到的事件必须按照严格的顺序一个接一个地出现，其中不能有其他任何事件插入。

![img-62.jpeg](img-62.jpeg)

## Page 110

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式

## 2 组合模式

### (2) 宽松连续性

宽松连续性要求组合模式中不同个体模式检测到的事件顺序出现，但每个事件之间可以有其他事件插入。

![img-63.jpeg](img-63.jpeg)

## Page 111

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

模式

## 2 组合模式

### (3) 非确定性放松连续性

非确定性放松连续性要求组合模式中不同个体模式检测到的事件顺序出现，并允许每个事件之间有其他事件插入，还可以重复使用已经检测过的事件。

![img-64.jpeg](img-64.jpeg)

## Page 112

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

模式

## 2 组合模式

循环模式内的连续性规则

### 严格连续性

严格连续性要求连续出现同样特征的多个事件之间不能存在其他事件。

### 非确定性放松连续性

非确定性放松连续性则允许连续出现同样特征的多个事件之间存在其他事件，并且可以重复使用已检测过的事件。

![img-65.jpeg](img-65.jpeg)
严格连续性

![img-66.jpeg](img-66.jpeg)
非确定性放松连续性

## Page 113

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 模式的定义

在Flink的CEP库中，可以使用模式API（Pattern API）来定义模式。模式API提供了Pattern类，通过该类的一些方法可以定义模式。

![img-67.jpeg](img-67.jpeg)

## Page 114

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

Pattern类提供了多种方法来定义个体模式。不同的方法定义的个体模式在组合模式中代表着不同的含义。

|  方法 | 含义  |
| --- | --- |
|  begin() | begin()方法定义的个体模式必须作为模式序列的开头，每个组合模式内只允许包含一个用begin()方法定义的个体模式。  |
|  next() | next()方法定义的个体模式与其他个体模式连接时，连续性规则为严格连续性。  |
|  followedBy() | followedBy()方法定义的个体模式与其他个体模式连接时，连续性规则为宽松连续性。  |
|  followedByAny() | followedByAny()方法定义的个体模式与其他个体模式连接时，连续性规则为非确定性放松连续性。  |

114

## Page 115

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 1 定义个体模式

### (1) 定义单例模式类型的个体模式

以next()方法为例，介绍定义单例模式的程序结构，具体如下。

```java
Pattern<eventtype,conditionstype> pattern
= Pattern.<eventtype>next("patternName");
```

115</eventtype></eventtype,conditionstype>

## Page 116

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 1 定义个体模式

### 2. 定义循环模式类型的个体模式

定义循环模式的个体模式时，需要在定义个体模式的方法后面追加量词，量词的作用是定义连续出现相同特征事件的检测次数。模式API提供了4种方法定义量词。

(1) oneOrMore()方法用于检测数据流中连续出现1~N次相同特征的事件，使用该方法的语法格式如下。

```mermaid
graph TD
A[Function.oneOrMore()] --&gt; B[数据流]
B --&gt; C[循环模式]
C --&gt; D[检测结果]
```

![img-68.jpeg](img-68.jpeg)

## Page 117

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 1 定义个体模式

### (2) 定义循环模式类型的个体模式

定义循环模式的个体模式时，需要在定义个体模式的方法后面追加量词，量词的作用是定义连续出现相同特征事件的检测次数。模式API提供了4种方法定义量词。

(2) times()方法用于检测数据流中连续出现固定次数或指定次数范围的相同特征的事件，使用该方法的语法格式如下。

![img-69.jpeg](img-69.jpeg)

![img-70.jpeg](img-70.jpeg)

![img-71.jpeg](img-71.jpeg)

## Page 118

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 1 定义个体模式

### (2) 定义循环模式类型的个体模式

定义循环模式的个体模式时，需要在定义个体模式的方法后面追加量词，量词的作用是定义连续出现相同特征事件的检测次数。模式API提供了4种方法定义量词。

(3) timesOrMore()方法用于检测数据流中连续出现fromtime~N次相同特征的事件，其中fromtime为用户定义的值，表示起始范围，使用该方法的语法格式如下。

```plaintext
function.timesOrMore(fromtime)
```

![img-72.jpeg](img-72.jpeg)

## Page 119

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 1 定义个体模式

### (2) 定义循环模式类型的个体模式

定义循环模式的个体模式时，需要在定义个体模式的方法后面追加量词，量词的作用是定义连续出现相同特征事件的检测次数。模式API提供了4种方法定义量词。

(4) greedy()方法基于oneOrMore()、times()或timesOrMore()方法使用，该方法会尽可能多地去检测相同特征的事件连续出现的次数，使用该方法的语法格式如下。

quantifiersFunction.greedy()

![img-73.jpeg](img-73.jpeg)
timesOrMore(2).greedy()

## Page 120

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 1 定义个体模式

### (2) 定义循环模式类型的个体模式

定义循环模式的个体模式时，需要在定义个体模式的方法后面追加量词，量词的作用是定义连续出现相同特征事件的检测次数。模式API提供了4种方法定义量词。

(5) optional()方法基于oneOrMore()、times()或timesOrMore()方法使用，表示当未检测到数据流中连续出现相同特征的事件时则进行忽略，使用该方法的语法格式如下。

```java
quantifiersFunction.optional()
```

120

## Page 121

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 1 定义个体模式

**定义循环模式内的连续性规则**

默认情况下，循环模式内的连续性规则为宽松连续性，如果想要定义循环模式内的连续性规则为严格连续性或非确定性放松连续性，则需要在定义量词的方法后边追加consecutive()或allowCombinations()方法。

![img-74.jpeg](img-74.jpeg)

## Page 122

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 2 定义个体模式的条件

### 定义个体模式的条件

定义完个体模式后，为了对数据流中的事件进行筛选，判断是否选取当前事件，还需要为个体模式定义条件。Pattern类提供了where()、or()和until()方法来定义不同类型的条件。

![img-75.jpeg](img-75.jpeg)

## Page 123

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 2 定义个体模式的条件

### (1) where()方法

where()方法用于为个体模式定义简单条件、迭代条件和组合条件。

(a) 使用where()方法定义简单条件时，需要在where()方法中传入一个SimpleCondition类的实例做为参数，并且重写SimpleCondition类的filter()方法来定义筛选数据流中事件的规则。语法格式如下。

```java
pattern.individualPattern.where(new SimpleCondition<eventtype>() {
@Override
public boolean filter(EventType event) throws Exception {
return judgeResult;
}
});
```

```java
Pattern<event, event=""> beginPattern =
Pattern.<event>begin("start").oneOrMore()
.where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getGender().equals("man");
}
});
```

123</event></event></event,></eventtype>

## Page 124

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 2 定义个体模式的条件

### (1) where()方法

where()方法用于为个体模式定义简单条件、迭代条件和组合条件。

(b) 使用where()方法定义迭代条件时，需要在where()方法中传入一个IterativeCondition类的实例作为参数，并且重写IterativeCondition类的filter()方法来定义筛选数据流中事件的规则。语法格式如下。

```java
pattern.individualPattern.where(new IterativeCondition<eventtype>() { @Override public boolean filter(EventType event, Context<eventtype, int="" int)="" public="" return="" the="" {="" {="" }="" }="" };="" };="" };="" };};};};};};};};};};};};};};};};};};};};};};};};};}

## Page 125

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 2 定义个体模式的条件

### (1) where()方法

where()方法用于为个体模式定义简单条件、迭代条件和组合条件。

(c) 使用where()方法定义组合条件时，表示将两个条件通过逻辑运算符AND（逻辑与）相连形成新的条件。从代码层面来说，就是在where()方法后边再次追加where()方法，使这两个where()方法定义的条件进行连接。

```java
Pattern<event, event=""> beginPattern =
Pattern.<event>begin("start")
.where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("zhangsan");
}
})
.where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getGender().equals("man");
}
});
```

125</event></event></event,>

## Page 126

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 2 定义个体模式的条件

### (2) or()方法

or()方法主要作用是基于where()方法定义组合条件，表示将两个条件通过逻辑运算符OR（逻辑或）相连形成新的条件。从代码层面来说，就是在where()方法后边追加or()方法，使where()和or()方法定义的条件进行连接。

or()方法可以传入一个SimpleCondition类的实例做为参数定义为简单条件，也可以传入一个IterativeCondition类的实例做为参数定义为迭代条件。

```java
Pattern<event, event=""> beginPattern = Pattern.<event>begin("start")
.where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("zhangsan");
}
})
.or(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("lisi");
}
});
```

126</event></event></event,>

## Page 127

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 2 定义个体模式的条件

### (3) until()方法

until()方法为循环模式的个体模式定义终止条件，通常应用于timesOrMore()和oneOrMore()方法定义的循环模式。until()方法可以传入一个SimpleCondition类的实例做为参数定义为简单条件，也可以传入一个IterativeCondition类的实例做为参数定义为迭代条件。

```java
Pattern<event, event=""> beginPattern = Pattern.<event>begin("start")
.oneOrMore()
.where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("zhangsan");
}
})
.until(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("lisi");
}
});
```

127</event></event></event,>

## Page 128

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 2 定义个体模式的条件

### 限定事件子类型

Pattern类提供了subtype()方法用于限定事件子类型，可以在定义个体模式方法的后边追加subtype()方法，并传递一个数据类型的类做为参数即可。当个体模式限定事件子类型之后，数据流中数据类型与限定事件子类型一致的事件，才会被个体模式定义的条件进行判断，这样可以有针对性检测数据流的事件，避免不必要的资源浪费，例如只想检测数据类型为实体类Event的事件，则代码如下。

```java
subtype(Event.calss)
```

128

## Page 129

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 3 定义组合模式

组合模式的定义是将已定义的个体模式按照复杂事件的检测规则连接起来。每个组合模式必须有一个使用begin()方法定义的个体模式作为起点，并且每个组合模式中只能包含一个使用begin()方法定义的个体模式。

![img-76.jpeg](img-76.jpeg)

Pattern<event, event=""> combiningPattern = Pattern.<event>begin("start")
.oneOrMore()
.where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("a");
}
})
.next("middle").where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("b");
}
})
.followedBy("end").where(new SimpleCondition<event>() {
@Override
public boolean filter(Event event) throws Exception {
return event.getUsername().equals("c");
}
});</event></event></event,></event,>

## Page 130

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 4 模式组

通常情况下，在Flink应用程序中定义的组合模式，可以解决企业对于大部分检测数据流中复杂事件的业务需求，不过在有些需要检测数据流中特别复杂的复杂事件时，可能会将组合模式划分为多个阶段，每个阶段可以看作是一个单独的组合模式，为了应对这样的需求，Flink CEP允许以“嵌套”的方式来定义模式，从而形成模式组。

![img-77.jpeg](img-77.jpeg)

```javascript
Pattern<event, event=""> combiningPattern = Pattern.begin(Pattern.<event>begin("start_start") .where(new SimpleCondition<event>() { @Override public boolean filter(Event event) throws Exception { return event.getUsername().equals("a"); } }).next("start_end").where(new SimpleCondition<event>() { @Override public boolean filter(Event event) throws Exception { return event.getUsername().equals("b"); } }))
.next("end").where(new SimpleCondition<event>() { @Override public boolean filter(Event event) throws Exception { return event.getUsername().equals("c"); } });
```

130</event></event></event></event,>

## Page 131

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 模式的定义

## 5 匹配后跳过策略

### 匹配后跳过策略

在 Flink CEP 中，对于类型为循环模式的个体模式，存在非确定性放松连续性的连续性规则，这会导致同一个事件被重复利用并分配到不同的复杂事件检测结果中，从而导致结果冗余和规模增大。为了精确控制事件匹配后跳过哪些情况，可以使用匹配后跳过策略（After Match Skip Strategy）。

![img-78.jpeg](img-78.jpeg)

## Page 132

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 使用模式检测数据流

在模式API中提供了CEP类，该类提供了一个pattern()方法可以将数据流和定义的模式作为参数传入，从而实现将定义的模式应用到数据流中，其程序结构如下。

PatternStream<datatype> patternName = CEP,pattern(dataStream,pattern);

将模式应用到数据流之后便可以检测出特定的复杂事件，对于检测到的复杂事件通常会进行进一步处理，PatternStream类提供了多种方法用于对复杂事件进行转换操作，并最终将PatternStream类的对象转换为数据流，即DataStream对象。

PatternStream的转换操作分为选择（Select）操作和处理（Process）操作。

![img-79.jpeg](img-79.jpeg)</datatype>

## Page 133

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 使用模式检测数据流

## 1. 选择操作

选择操作可以看作是处理操作向上封装的结果，可以使用户更加便捷地处理复杂事件，不过相对于更加底层的处理操作来说，用户使用选择操作来处理复杂事件的功能是有限的。模式API提供了两种方法使用选择操作，分别是select()方法和flatSelect()方法。

(1) select()方法可以将数据流中检测到的复杂事件提取出来，并转换为想要的形式进行输出，每个复杂事件对应转换结果的一个事件，其程序结构如下。

```java
DataStream<outEventType> selectDataStream = pattern.select(new PatternSelectFunction<eventtype,outeventtype>() {
@Override
public EventType select(Map<patternnametype,list<eventtype>&gt; map) throws Exception {
return result;
}
});
```

133</patternnametype,list></eventtype></outEventType>

## Page 134

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 使用模式检测数据流

## 1. 选择操作

选择操作可以看作是处理操作向上封装的结果，可以使用户更加便捷地处理复杂事件，不过相对于更加底层的处理操作来说，用户使用选择操作来处理复杂事件的功能是有限的。模式API提供了两种方法使用选择操作，分别是select()方法和flatSelect()方法。

(2) flatSelect()方法可以将数据流中检测到的复杂事件提取出来，并转换为想要形式进行输出，每个复杂事件可以对应转换结果的多个事件，其程序结构如下。

```java
DataStream<outeventtype> selectDataStream = pattern.flatselect(new PatternFlatSelectFunction<eventtype,outeventtype>() {
@Override
public void select(Map<patternnametype,list<eventtype>&gt; map,
Collector<outeventtype> collector) throws Exception {
collector.collect(result);
}
});
```

134</outeventtype></eventtype></outeventtype></eventtype>

## Page 135

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 使用模式检测数据流

## 2. 处理操作

处理操作在选择操作的基础上为用户提供了一个上下文对象，用户可以通过该对象将复杂事件中的事件输出到Side Outputs的标签。模式API提供了process()方法使用处理操作，其程序结构如下。

```java
DataStream<outeventtype> processDataStream = pattern.process(new PatternProcessFunction<eventtype,outeventtype>() {
@Override
public void processMatch(
Map<patternnametype, list<eventtype="">&gt; map,
Context context,
Collector<outeventtype> collector) throws Exception {
collector.collect(result);
}
});
```

135</outeventtype></eventtype,outeventtype></outeventtype>

## Page 136

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 处理超时事件

通过Flink CEP检测数据流中的复杂事件时，可以为定义的模式指定一个时间限制，该时间限制可以理解为组合模式的模式序列中第一个事件到最后一个事件之间的最大时间间隔，只有在这期间成功检测的复杂事件才是有效的，超出这期间检测的复杂事件则认为是失败的，不过这种失败跟没有检测到复杂事件不同，它其实是一种部分检测成功的情况，因为模式序列的第一个事件被成功检测到，只不过没有在规定时间内检测到模式序列的最后一个事件，像这种超时的事件，往往不应该直接丢弃，而是作为提示或警告进行输出，这就是对超时事件的处理。

![img-80.jpeg](img-80.jpeg)

## Page 137

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 处理超时事件

模式API提供了within()方法为定义的模式指定时间限制，可以在组合模式的最后一个个体模式追加within()方法，并传入时间单位作为参数来指定时间限制。

|  时间单位 | 语法格式  |
| --- | --- |
|  毫秒 | Time.milliseconds(times)  |
|  秒 | Time.seconds(times)  |
|  分 | Time.minutes(times)  |
|  时 | Time.hours(times)  |
|  天 | Time.days(times)  |

137

## Page 138

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 处理超时事件

```java
public class MyCustomizationClass extends PatternProcessFunction <eventtype,outeventtype> implements TimedOutPartialMatchHandler <eventtype> { @Override public void processMatch( Map <patternnametype, list<eventtype="">&gt; map, Context context, Collector<outeventtype> collector) throws Exception { } @Override public void processTimedOutMatch( Map <patternnametype, list<eventtype="">&gt; map, Context context) throws Exception { } }
```

通过代码实现超时事件的处理时，用户需要定义一个实现TimedOutPartialMatchHandler接口和继承PatternProcessFunction类的自定义类，并且在process()方法中实例化自定义类。

138</patternnametype></patternnametype,></eventtype></eventtype></eventtype>

## Page 139

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 处理超时事件

## 其他处理超时事件的方法

除了通过用户自定义类实现TimedOutPartialMatchHandler接口和继承PatternProcessFunction类来处理超时事件之外，模式API还提供了基于select()和flatSelect()方法实现便捷处理超时事件的方式。

使用select()方法处理超时事件时，需要在方法内传入Side Outputs的标签、PatternTimeoutFunction类的实例和PatternSelectFunction类的实例这3个参数。

使用flatSelect()方法处理超时事件时，同样需要在方法内传入3个参数，它们分别是Side Outputs的标签、PatternFlatTimeoutFunction类的实例和PatternFlatSelectFunction类的实例。

139

## Page 140

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

CEP代码流程

```cpp
StreamExecutionEnvironment env = ...;
DataStream<event> input = ...;
DataStream<event> partitionedInput = input.keyBy(new KeySelector<event, integer="">() {
@Override
public Integer getKey(Event value) throws Exception {
return value.getId();
}
});
Pattern<event, ?=""> pattern = Pattern.<event>begin("start")
.next("middle")
.where(SimpleCondition.of(value -&gt; value.getName().equals("error"))))
.followedBy("end")
.where(SimpleCondition.of(value -&gt; value.getName().equals("critical"))))
.within(Duration.ofSeconds(10));
PatternStream<event> patternStream = CEP.pattern(partitionedInput, pattern);
DataStream<alert> alerts = patternStream.select(new PatternSelectFunction<event, alert="">() {
@Override
public Alert select(Map<string, list<event="">&gt; pattern) throws Exception {
return createAlert(pattern);
}
});
```

140</event,></event></event,></event></event,></event></event,></event>

## Page 141

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 处理延迟事件

## 处理延迟事件

在Flink CEP中可以沿用设置水位线的方式来处理延迟到达的事件，当一个事件到来时，并不会被Flink CEP立即检测，而是先放入一个缓冲区，缓冲区内的事件会按照事件时间由小到大进行排序，当设置水位线的时间戳到达时，就会将缓冲区内所有事件时间小于水位线时间戳的事件全部取出来进行检测。

不过设置的水位线并不能保证所有乱序数据全都放入缓冲区内在被Flink CEP进行检测，总会有一些延迟比较严重的事件，以至于该类型的事件到达时水位线早已超过了它的时间戳。不过实际应用场景中，如果不想丢弃数据流中的任何一个事件，这时便可以借鉴窗口操作处理延迟比较严重的事件，将这一类事件输出到Side Outputs的标签另行处理。

![img-81.jpeg](img-81.jpeg)

## Page 142

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

# 处理延迟事件

模式API提供了sideOutputLateData()方法用于将延迟比较严重的事件输出到Side Outputs的标签，可以在PatternStream对象调用select()、flatSelect()或process()方法处理复杂事件之前，调用sideOutputLateData()方法，并传入一个Side Outputs的标签作为参数即可，其语法格式如下。

```
pattern.sideOutputLateData(outPutTag)
.select(……)/flatSelect(……)/process(……)
```

142

## Page 143

*Metadata:*
- Width: 2000
- Height: 1500
- DPI: 200

谢谢！

---

## Extracted Images

Total images found: 82

### Image 1

- **ID**: `img-0.jpeg`
- **Position**: (154, 425) to (1762, 927)
- **Size**: 1608 × 502 pixels

### Image 2

- **ID**: `img-1.jpeg`
- **Position**: (412, 911) to (1592, 1220)
- **Size**: 1180 × 309 pixels

### Image 3

- **ID**: `img-2.jpeg`
- **Position**: (312, 865) to (902, 1179)
- **Size**: 590 × 314 pixels

### Image 4

- **ID**: `img-3.jpeg`
- **Position**: (1014, 865) to (1716, 1144)
- **Size**: 702 × 279 pixels

### Image 5

- **ID**: `img-4.jpeg`
- **Position**: (74, 634) to (1030, 1238)
- **Size**: 956 × 604 pixels

### Image 6

- **ID**: `img-5.jpeg`
- **Position**: (74, 241) to (1154, 925)
- **Size**: 1080 × 684 pixels

### Image 7

- **ID**: `img-6.jpeg`
- **Position**: (336, 612) to (1328, 1308)
- **Size**: 992 × 696 pixels

### Image 8

- **ID**: `img-7.jpeg`
- **Position**: (670, 360) to (856, 535)
- **Size**: 186 × 175 pixels

### Image 9

- **ID**: `img-8.jpeg`
- **Position**: (670, 642) to (856, 820)
- **Size**: 186 × 178 pixels

### Image 10

- **ID**: `img-9.jpeg`
- **Position**: (670, 918) to (856, 1097)
- **Size**: 186 × 179 pixels

### Image 11

- **ID**: `img-10.jpeg`
- **Position**: (260, 937) to (960, 1350)
- **Size**: 700 × 413 pixels

### Image 12

- **ID**: `img-11.jpeg`
- **Position**: (978, 937) to (1670, 1350)
- **Size**: 692 × 413 pixels

### Image 13

- **ID**: `img-12.jpeg`
- **Position**: (328, 612) to (962, 1066)
- **Size**: 634 × 454 pixels

### Image 14

- **ID**: `img-13.jpeg`
- **Position**: (982, 612) to (1618, 1132)
- **Size**: 636 × 520 pixels

### Image 15

- **ID**: `img-14.jpeg`
- **Position**: (144, 705) to (1778, 1424)
- **Size**: 1634 × 719 pixels

### Image 16

- **ID**: `img-15.jpeg`
- **Position**: (194, 658) to (1708, 994)
- **Size**: 1514 × 336 pixels

### Image 17

- **ID**: `img-16.jpeg`
- **Position**: (256, 586) to (1668, 936)
- **Size**: 1412 × 350 pixels

### Image 18

- **ID**: `img-17.jpeg`
- **Position**: (588, 1011) to (1272, 1476)
- **Size**: 684 × 465 pixels

### Image 19

- **ID**: `img-18.jpeg`
- **Position**: (1004, 738) to (1794, 1291)
- **Size**: 790 × 553 pixels

### Image 20

- **ID**: `img-19.jpeg`
- **Position**: (232, 639) to (1624, 1020)
- **Size**: 1392 × 381 pixels

### Image 21

- **ID**: `img-20.jpeg`
- **Position**: (202, 694) to (1682, 990)
- **Size**: 1480 × 296 pixels

### Image 22

- **ID**: `img-21.jpeg`
- **Position**: (130, 874) to (1794, 1384)
- **Size**: 1664 × 510 pixels

### Image 23

- **ID**: `img-22.jpeg`
- **Position**: (266, 816) to (1640, 1318)
- **Size**: 1374 × 502 pixels

### Image 24

- **ID**: `img-23.jpeg`
- **Position**: (316, 895) to (1680, 1369)
- **Size**: 1364 × 474 pixels

### Image 25

- **ID**: `img-24.jpeg`
- **Position**: (526, 720) to (1394, 1408)
- **Size**: 868 × 688 pixels

### Image 26

- **ID**: `img-25.jpeg`
- **Position**: (466, 790) to (1346, 1390)
- **Size**: 880 × 600 pixels

### Image 27

- **ID**: `img-26.jpeg`
- **Position**: (582, 861) to (1366, 1408)
- **Size**: 784 × 547 pixels

### Image 28

- **ID**: `img-27.jpeg`
- **Position**: (1290, 911) to (1776, 1434)
- **Size**: 486 × 523 pixels

### Image 29

- **ID**: `img-28.jpeg`
- **Position**: (42, 750) to (1802, 1399)
- **Size**: 1760 × 649 pixels

### Image 30

- **ID**: `img-29.jpeg`
- **Position**: (610, 813) to (818, 1207)
- **Size**: 208 × 394 pixels

### Image 31

- **ID**: `img-30.jpeg`
- **Position**: (230, 796) to (1418, 1034)
- **Size**: 1188 × 238 pixels

### Image 32

- **ID**: `img-31.jpeg`
- **Position**: (414, 511) to (1370, 927)
- **Size**: 956 × 416 pixels

### Image 33

- **ID**: `img-32.jpeg`
- **Position**: (866, 1171) to (1062, 1371)
- **Size**: 196 × 200 pixels

### Image 34

- **ID**: `img-33.jpeg`
- **Position**: (260, 712) to (984, 1338)
- **Size**: 724 × 626 pixels

### Image 35

- **ID**: `img-34.jpeg`
- **Position**: (1042, 712) to (1694, 1338)
- **Size**: 652 × 626 pixels

### Image 36

- **ID**: `img-35.jpeg`
- **Position**: (202, 933) to (1720, 1402)
- **Size**: 1518 × 469 pixels

### Image 37

- **ID**: `img-36.jpeg`
- **Position**: (446, 853) to (1360, 1414)
- **Size**: 914 × 561 pixels

### Image 38

- **ID**: `img-37.jpeg`
- **Position**: (426, 887) to (1250, 1399)
- **Size**: 824 × 512 pixels

### Image 39

- **ID**: `img-38.jpeg`
- **Position**: (434, 816) to (1378, 1365)
- **Size**: 944 × 549 pixels

### Image 40

- **ID**: `img-39.jpeg`
- **Position**: (708, 857) to (1678, 1416)
- **Size**: 970 × 559 pixels

### Image 41

- **ID**: `img-40.jpeg`
- **Position**: (330, 580) to (1400, 805)
- **Size**: 1070 × 225 pixels

### Image 42

- **ID**: `img-41.jpeg`
- **Position**: (326, 1051) to (1416, 1286)
- **Size**: 1090 × 235 pixels

### Image 43

- **ID**: `img-42.jpeg`
- **Position**: (436, 634) to (1674, 1393)
- **Size**: 1238 × 759 pixels

### Image 44

- **ID**: `img-43.jpeg`
- **Position**: (360, 520) to (1434, 753)
- **Size**: 1074 × 233 pixels

### Image 45

- **ID**: `img-44.jpeg`
- **Position**: (380, 1132) to (1462, 1377)
- **Size**: 1082 × 245 pixels

### Image 46

- **ID**: `img-45.jpeg`
- **Position**: (202, 1000) to (1788, 1238)
- **Size**: 1586 × 238 pixels

### Image 47

- **ID**: `img-46.jpeg`
- **Position**: (526, 845) to (1334, 1286)
- **Size**: 808 × 441 pixels

### Image 48

- **ID**: `img-47.jpeg`
- **Position**: (626, 775) to (1388, 1384)
- **Size**: 762 × 609 pixels

### Image 49

- **ID**: `img-48.jpeg`
- **Position**: (558, 924) to (1354, 1443)
- **Size**: 796 × 519 pixels

### Image 50

- **ID**: `img-49.jpeg`
- **Position**: (486, 922) to (1440, 1417)
- **Size**: 954 × 495 pixels

### Image 51

- **ID**: `img-50.jpeg`
- **Position**: (426, 718) to (1562, 1365)
- **Size**: 1136 × 647 pixels

### Image 52

- **ID**: `img-51.jpeg`
- **Position**: (306, 499) to (1476, 1129)
- **Size**: 1170 × 630 pixels

### Image 53

- **ID**: `img-52.jpeg`
- **Position**: (694, 382) to (870, 550)
- **Size**: 176 × 168 pixels

### Image 54

- **ID**: `img-53.jpeg`
- **Position**: (694, 661) to (870, 835)
- **Size**: 176 × 174 pixels

### Image 55

- **ID**: `img-54.jpeg`
- **Position**: (694, 940) to (870, 1113)
- **Size**: 176 × 173 pixels

### Image 56

- **ID**: `img-55.jpeg`
- **Position**: (1398, 528) to (1800, 1140)
- **Size**: 402 × 612 pixels

### Image 57

- **ID**: `img-56.jpeg`
- **Position**: (176, 459) to (1746, 730)
- **Size**: 1570 × 271 pixels

### Image 58

- **ID**: `img-57.jpeg`
- **Position**: (182, 808) to (1750, 1075)
- **Size**: 1568 × 267 pixels

### Image 59

- **ID**: `img-58.jpeg`
- **Position**: (498, 1084) to (682, 1450)
- **Size**: 184 × 366 pixels

### Image 60

- **ID**: `img-59.jpeg`
- **Position**: (600, 598) to (1154, 1108)
- **Size**: 554 × 510 pixels

### Image 61

- **ID**: `img-60.jpeg`
- **Position**: (1092, 1156) to (1806, 1282)
- **Size**: 714 × 126 pixels

### Image 62

- **ID**: `img-61.jpeg`
- **Position**: (1438, 526) to (1836, 1138)
- **Size**: 398 × 612 pixels

### Image 63

- **ID**: `img-62.jpeg`
- **Position**: (454, 661) to (1566, 1261)
- **Size**: 1112 × 600 pixels

### Image 64

- **ID**: `img-63.jpeg`
- **Position**: (442, 676) to (1506, 1254)
- **Size**: 1064 × 578 pixels

### Image 65

- **ID**: `img-64.jpeg`
- **Position**: (442, 675) to (1506, 1252)
- **Size**: 1064 × 577 pixels

### Image 66

- **ID**: `img-65.jpeg`
- **Position**: (1052, 616) to (1836, 754)
- **Size**: 784 × 138 pixels

### Image 67

- **ID**: `img-66.jpeg`
- **Position**: (1052, 891) to (1836, 1149)
- **Size**: 784 × 258 pixels

### Image 68

- **ID**: `img-67.jpeg`
- **Position**: (1306, 357) to (1706, 970)
- **Size**: 400 × 613 pixels

### Image 69

- **ID**: `img-68.jpeg`
- **Position**: (442, 826) to (1378, 1297)
- **Size**: 936 × 471 pixels

### Image 70

- **ID**: `img-69.jpeg`
- **Position**: (166, 790) to (852, 1159)
- **Size**: 686 × 369 pixels

### Image 71

- **ID**: `img-70.jpeg`
- **Position**: (920, 648) to (1800, 877)
- **Size**: 880 × 229 pixels

### Image 72

- **ID**: `img-71.jpeg`
- **Position**: (920, 927) to (1800, 1261)
- **Size**: 880 × 334 pixels

### Image 73

- **ID**: `img-72.jpeg`
- **Position**: (522, 804) to (1340, 1294)
- **Size**: 818 × 490 pixels

### Image 74

- **ID**: `img-73.jpeg`
- **Position**: (408, 865) to (1556, 1238)
- **Size**: 1148 × 373 pixels

### Image 75

- **ID**: `img-74.jpeg`
- **Position**: (1328, 597) to (1728, 1209)
- **Size**: 400 × 612 pixels

### Image 76

- **ID**: `img-75.jpeg`
- **Position**: (1330, 526) to (1728, 1138)
- **Size**: 398 × 612 pixels

### Image 77

- **ID**: `img-76.jpeg`
- **Position**: (32, 586) to (1220, 1209)
- **Size**: 1188 × 623 pixels

### Image 78

- **ID**: `img-77.jpeg`
- **Position**: (70, 640) to (1280, 1203)
- **Size**: 1210 × 563 pixels

### Image 79

- **ID**: `img-78.jpeg`
- **Position**: (610, 745) to (1862, 1500)
- **Size**: 1252 × 755 pixels

### Image 80

- **ID**: `img-79.jpeg`
- **Position**: (1230, 642) to (1556, 1132)
- **Size**: 326 × 490 pixels

### Image 81

- **ID**: `img-80.jpeg`
- **Position**: (1470, 523) to (1872, 1140)
- **Size**: 402 × 617 pixels

### Image 82

- **ID**: `img-81.jpeg`
- **Position**: (1486, 548) to (1882, 1162)
- **Size**: 396 × 614 pixels

---

*Generated by Mistral OCR MCP Server*
